{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': np.float64(2.195254015709299), 'penalty': 'l1'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "iris = load_iris()\n",
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
    "                              random_state=0)\n",
    "distributions = dict(C=uniform(loc=0, scale=4),\n",
    "                     penalty=['l2', 'l1'])\n",
    "clf = RandomizedSearchCV(logistic, distributions, random_state=0)\n",
    "search = clf.fit(iris.data, iris.target)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00092397, 0.0018003 , 0.00142837, 0.00101542]),\n",
       " 'std_fit_time': array([0.00025633, 0.00081025, 0.00030957, 0.00022945]),\n",
       " 'mean_score_time': array([0.00052872, 0.00113888, 0.00089946, 0.00059228]),\n",
       " 'std_score_time': array([4.96837319e-05, 2.83613763e-04, 2.35238980e-04, 1.41539406e-04]),\n",
       " 'param_C': masked_array(data=[1, 1, 10, 10],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value=999999),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value=np.str_('?'),\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.96666667, 0.96666667, 1.        , 0.96666667]),\n",
       " 'split1_test_score': array([1.        , 0.96666667, 1.        , 1.        ]),\n",
       " 'split2_test_score': array([0.96666667, 0.96666667, 0.9       , 0.96666667]),\n",
       " 'split3_test_score': array([0.96666667, 0.93333333, 0.96666667, 0.96666667]),\n",
       " 'split4_test_score': array([1., 1., 1., 1.]),\n",
       " 'mean_test_score': array([0.98      , 0.96666667, 0.97333333, 0.98      ]),\n",
       " 'std_test_score': array([0.01632993, 0.02108185, 0.03887301, 0.01632993]),\n",
       " 'rank_test_score': array([1, 4, 3, 1], dtype=int32)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 0.93 seconds for 15 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.993 (std: 0.011)\n",
      "Parameters: {'alpha': np.float64(0.9618041303454363), 'average': False, 'l1_ratio': np.float64(0.014040963651391625)}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.985 (std: 0.013)\n",
      "Parameters: {'alpha': np.float64(0.054369578159338315), 'average': False, 'l1_ratio': np.float64(0.4285242701765367)}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.985 (std: 0.013)\n",
      "Parameters: {'alpha': np.float64(0.05071592069277454), 'average': False, 'l1_ratio': np.float64(0.06174162393126825)}\n",
      "\n",
      "GridSearchCV took 4.22 seconds for 60 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.993 (std: 0.007)\n",
      "Parameters: {'alpha': np.float64(0.1), 'average': False, 'l1_ratio': np.float64(0.3333333333333333)}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.989 (std: 0.022)\n",
      "Parameters: {'alpha': np.float64(0.1), 'average': False, 'l1_ratio': np.float64(0.7777777777777777)}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.989 (std: 0.007)\n",
      "Parameters: {'alpha': np.float64(0.01), 'average': False, 'l1_ratio': np.float64(0.6666666666666666)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# get some data\n",
    "X, y = load_digits(return_X_y=True, n_class=3)\n",
    "\n",
    "# build a classifier\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"elasticnet\", fit_intercept=True)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\n",
    "    \"average\": [True, False],\n",
    "    \"l1_ratio\": stats.uniform(0, 1),\n",
    "    \"alpha\": stats.loguniform(1e-2, 1e0),\n",
    "}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 15\n",
    "random_search = RandomizedSearchCV(\n",
    "    clf, param_distributions=param_dist, n_iter=n_iter_search\n",
    ")\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\n",
    "    \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n",
    "    % ((time() - start), n_iter_search)\n",
    ")\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\n",
    "    \"average\": [True, False],\n",
    "    \"l1_ratio\": np.linspace(0, 1, num=10),\n",
    "    \"alpha\": np.power(10, np.arange(-2, 1, dtype=float)),\n",
    "}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\n",
    "    \"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "    % (time() - start, len(grid_search.cv_results_[\"params\"]))\n",
    ")\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'min_samples_split': 5, 'n_estimators': 9}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"min_samples_split\": [5, 10]}\n",
    "search = HalvingGridSearchCV(clf, param_grid, resource='n_estimators',\n",
    "                             max_resources=10,\n",
    "                             random_state=0).fit(X, y)\n",
    "search.best_params_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_samples_split': 3, 'n_estimators': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from scipy.stats import randint\n",
    "import numpy as np\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "np.random.seed(0)\n",
    "param_distributions = {\"max_depth\": [3, None],\n",
    "                       \"min_samples_split\": randint(2, 11)}\n",
    "search = HalvingRandomSearchCV(clf, param_distributions,\n",
    "                               resource='n_estimators',\n",
    "                               max_resources=10,\n",
    "                               random_state=0).fit(X, y)\n",
    "search.best_params_  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "develop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
